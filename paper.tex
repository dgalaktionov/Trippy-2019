% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\usepackage{enumerate}
\usepackage{marginnote}
\usepackage[linesnumbered,commentsnumbered,boxed]{algorithm2e}
\usepackage{amsmath}

\newcommand{\acumm}{T-Matrices} % T is for Total!
\newcommand{\ctr}{NewCTR (name subject to change)\ }

\begin{document}
%
\title{Next Trippy Structures\thanks{Supported by organization x.}}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{First Author\inst{1}\orcidID{0000-1111-2222-3333} \and
Second Author\inst{2,3}\orcidID{1111-2222-3333-4444} \and
Third Author\inst{3}\orcidID{2222--3333-4444-5555}}
%
\authorrunning{F. Author et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Princeton University, Princeton NJ 08544, USA \and
Springer Heidelberg, Tiergartenstr. 17, 69121 Heidelberg, Germany
\email{lncs@springer.com}\\
\url{http://www.springer.com/gp/computer-science/lncs} \and
ABC Institute, Rupert-Karls-University Heidelberg, Heidelberg, Germany\\
\email{\{abc,lncs\}@uni-heidelberg.de}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
The abstract should briefly summarize the contents of the paper in
15--250 words.

\keywords{First keyword  \and Second keyword \and Another keyword.}
\end{abstract}
%
%
%
\section{Introduction: sin hacer (queda para el final)}
We took the idea from our SPIRE paper and we made it great, using ZSTD compression and other tricks to improve the time complexity of the queries for the \ctr. Regarding \acumm, it was not possible to improve its speed (as it was already a few memory accesses per query), but we managed to compress it without increasing time complexity. We rock.

If possible, cite applications of our kind of analysis for transportat/ad companies, to show that what we are doing is useful. One example is \cite{tu2018spatial}. Another is \cite{zhang2017targeted}. And by the way, the guys in \cite{weng2018mining} do some analysis with data that has already boarding and alighting stops!

These guys \cite{wang2014aggregated} made it so boring that they are probably not worth citing, but I'm keeping them here for now because they separate fridays and types of days, even though we don't care much about that anymore. OR DO WE?

Aqui no estaria mal, ademas de motivar ;) completar con la estructura del paper, y de paso decir que es lo nuevo VS lo de SPIRE. (ej. Esta es una version extendida del X, donde hemos tratado de solucionar nuevas operaciones como x..., viendo que algunas de ellas se volvían ineficientes en el CTR original, decidimos realizar una nueva variante (\ctr), que permite responder más consultas eficientemente. Así, en la Seccion 2 T-R, en la seccon 3 - MODELO , en la seccion 4 mostramos nuestras propuestas y cómo utilizarlas para resolver consutlas... etc etc)



\section{Related works}
\subsection{Trajectory indexing}
Literature on spatial trajectory indexing can be categorized by the nature of the trajectories: they can be either constrained to a network or in free space (often called moving objects). While there are well-known queries for indexes that work on moving objects in free space \cite{DBLP:conf/vldb/PfoserJT00}, the network constrained trajectory indexes cover more diverse querying needs, as different networks involve different kinds of challenges (as in vehicular road network vs public transportation network), and also because the intended application may vary (analyzing trip-chaining patterns vs number of passengers within a time window). A comprehensive review on indexing methods can be found in \cite[Chapter 4]{DBLP:books/sp/PelekisT14}, to which we shall expand in the rest of this section to mention the most notable indexes and some new developments.

\subsubsection{Free trajectory indexing}
Several adaptations of the {\em R-Tree} \cite{DBLP:conf/sigmod/Guttman84} are widely used for the indexing of moving objects. The most common approach is to integrate the temporal dimension in the R-Tree itself, as found in the {\em STR-Tree} and the {\em TB-Tree} from \cite{DBLP:conf/vldb/PfoserJT00}.
Another common approach is to compliment the R-Tree with another similar structure, as has been done for the {\em MV3R-tree}~\cite{DBLP:conf/vldb/PapadiasT01},
where an Historical {\em R-Tree}~\cite{nascimento1998towards} to partition on the temporal dimension.

The observation that, even for free trajectories, temporal dimension is generally more selective than spatial dimensions was heavily exploited in the subsequent works, such as {\em SETI} from \cite{chakka2003indexing}, where the space is partitioned statically and the time is indexed with a one dimensional R-Tree.

Recently a framework based on Apache Spark was developed called {\em UlTraMan}~ \cite{ding2018ultraman}, that supports different kinds of partitioning schemes for large collections of trajectories to answer range, kNN or aggregation queries, allowing to repartition the dataset to maximize the query time efficiency for a given query type. Although UlTraMan has been tested over network constrained trajectories, it does not appear to be exploiting network information in any way, hence its inclusion in this category.

In the field of compact data structures, an index called {\em GraCT}~\cite{brisaboa2019gract} has been developed, based snapshots at regular time intervals using {\em k$^2$-Trees}~\cite{brisaboa2009k} and movement logs for individual trajectories to which grammar compression is applied with {\em RePair}~\cite{larsson2000off}. Because of this, GraCT is a self-indexed compact representation that supports spatio-temporal range and nearest-neighbor queries, as well as allowing for direct access to the trajectory information.

\subsubsection{Network constrained trajectory indexing}
There are also numerous approaches that use R-Tree based indexes for trajectories that are constrained to an underlying network, aiming to decrease the redundancy in the representation by separating the representation into levels. Examples of such indexes include the {\em FNR-Tree}~\cite{DBLP:conf/ssd/Frentzos03}, where the network elements are indexed with a 2D R-Tree and 1D R-Trees to index time intervals of moving objects along the edges of the network. Some of the limitations of the FNR-Tree are addressed in \cite{DBLP:journals/geoinformatica/AlmeidaG05}, where the authors propose the {\em MON-Tree}, where the moving objects are indexes in two dimensional R-Trees (the dimensions being edge position vs time). More recent alternatives also integrate {\em B$^+$-Trees}, which has proven to be more space and time efficient for indexing the temporal dimension as proven by the {\em TMN-Tree}~\cite{chang2010tmn}. Alternatively, in \cite{rivera2018faster} a compact representation of time intervals is proposed using two bitvectors, that can be combined with these R-Tree based indexes to increase the efficiency for temporal filtering. Refer to \cite{john2017performance} for a quick comparison of these R-Tree based indexes.

As a competitive alternative to these R-Tree based indexes, {\em PARINET}~\cite{DBLP:journals/vldb/PopaZOBV11}, that builds spatial partitions from the trajectories based on their distribution and network topology, and uses a B$^+$-Tree to index the trajectories in each partition by time intervals. Although candidate trajectories must be filtered in memory during queries, PARINET is highly efficient in practice as it minimizes the number of disk accesses needed.
%The same ideas were used in {\em TRIFL}~\cite{that2015trifl}, where the cost model is adapted for flash storage.

Another relevant representation is described in \cite{DBLP:conf/gis/KroghPTT14}. Their proposed index, {\em NETTRA}, was designed to efficiently solve a specific kind of query called {\em Strict Path Queries (SPQ)}, built on a traditional RDBMS with $B^+$-Tree indexes. Another distinctive feature of NETTRA is its treatment of network constrained trajectories as textual information, which allows to apply string matching techniques such as fingerprinting functions to determine what trajectories have similar paths on their traversed edges. This close equivalence between trajectories and strings has been further exploited by Geodabs~\cite{chapuis2018geodabs}, where both the spatial distribution and sequence information are taken into account for finding trajectories by similarity with fingerprinting. These text-based approaches are sometimes tangled with works on the topic of semantic trajectories such as \cite{al2017semantictraj}.

%For vehicles we also have this \cite{cai2018vector} and \cite{lovell2018lossless}.

A recent compact data structure names {\em CiNCT} has been proposed in \cite{koide2018cinct}, where trajectories are encoded into a string, that is used to build an FM-index \cite{DBLP:conf/focs/FerraginaM00} with a Huffman-shaped Wavelet Tree \cite{ferragina2009compressed}. To further save space, the string is constructed with relative movement labels instead of absolute edges, with an auxiliary structure that represents a network graph built from the input trajectories themselves. While this structure excels at pattern-matching and path extraction in vehicular networks (such as the streets of a city), it cannot be applied to our problems in public transportation networks.

\subsection{Trajectory data mining}
Currently there are several known techniques that would allow to collect data regarding users' trips over a public transportation network. Numerous works exist where these trajectories are mined from the transactions of smart cards \cite{bhaskar2015passenger,wang2014aggregated}. This can be complemented with information derived from GPS devices, as shown in \cite{ma2014development}. Alternatively, these trajectories may be extracted relying on positioning obtained from cellular networks, as proven by \cite{liu2017exploring}. 

In addition, the authors of \cite{tao2014exploring} have specifically tackled the challenge of reconstructing full trajectories, accounting for trip-chaining, using data obtained from smart cards. Furthermore, in \cite{alsger2016validating} it is also proven that not only the alighting stops, but also the (last) destination stop of a trip can be estimated from boarding data gathered by a smart card, within a reasonable accuracy.

This summarized review proves that, although we were not able to access real data from a public transportation company, such curated information about users' trips can indeed be obtained and used for our proposed representation.

\subsection{Underlying structures and algorithms}
\subsubsection{Summed Area Tables}
I mean maybe we should mention them :-)

\subsubsection{Bitvectors}
\label{sec:bit}
A great amount of works in Compressed Data Structures revolve around bitvectors, both compressed and uncompressed. For a bitvector $B[1,n]$ the following operations are expected to be supported:

\begin{itemize}
    \item $rank_1(B,i)$ returns the number of set bits in $B[1..i]$. Alternatively, $rank_0(B,i) = i - rank_1(B,i)$ and also $B[i] = rank_1(B,i-1) - rank_1(B,i)$.
    \item $select_1(B,i)$ returns the position in $1..n$ where the $i$th 1 occurs. Therefore, $rank_1(B,select_1(B,i)) = i$.
\end{itemize}

These operations can be supported in constant time with $o(n)$ extra bits \cite{Jac89,Mun96}, although several techniques exist for compressing bitvectors \cite{Raman:2002:SID:545381.545411,okanohara2007practical}. \marginpar{WTF is wrong with \cite{Golynski2007}?? I cannot find it, paywalls everywhere. Someone (Fari?) cited it before, but I am not going to cite something I cannot read...}

\subsubsection{Compressed Suffix Array (CSA)}
\label{sec:csa}
One common structure to count or locate all the occurrences of a pattern $P[1,m]$ in a string $S[1,n]$ of symbols from an alphabet $\Sigma$ is the Suffix Array (SA) \cite{MM93}. The SA lexicographically sorts all the suffix of $S$ and builds an array $A[1,n]$ with their indexes, holding that $S[A[i],n] \prec S[A[i+1],n]$. This allows to find out all the occurrences of a substring $P[1,m]$ in $O(m \log n)$ with binary searches.

A simple enhancement to avoid storing the original string $S$ is to align $A$ with a bitvector $D[1,n]$ where $D[i]=1~\Leftrightarrow~S[A[i-1]] \prec S[A[i]]$. That is, $D$ marks with a 1 all the indexes $i$ of $A$ where the starting symbol of that suffix $S[A[i]]$ has a larger lexicographical value than the one from the previous suffix $S[A[i-1]]$. With $D$, keeping $S$ is not longer needed as $S[A[i]] = rank_1(D,i)$, where $rank_1(D,i)$ returns the number of ones in $D[1..i]$.

Sadakane's CSA \cite{Sad03} further reduces the space by replacing $A$ with a permutation $\Psi[1,n]$ \cite{GV00}, where given $A[i]=k$ and $A[j]=k+1$, $\Psi[i]=j$, while keeping the capability to count the occurrences of $P[1,m]$ in $O(m \log n)$ as the bitvector $D$ is still valid for the entries of $\Psi$. Although an uncompressed $\Psi$ would have the same space requirement as $A$, it is much more compressible as it is formed by $\sigma$ strictly increasing subsequences, being $\sigma$ the size of the alphabet $\Sigma$. Furthermore, it has been proved in \cite{NM07} that $\Psi$ can be split in $nH_k+\sigma^k$ (for any $k$) runs of consecutive values. It is therefore possible to compress $\Psi$ using $\delta$-encoding and run-length for the (frequent) runs of consecutive values. This property has allowed \cite{FBNCPR12}, among others, to achieve compression rates comparable to gzip for English text, while maintaining relatively fast random access by storing samples at regular intervals.

\subsubsection{Wavelet Matrix (WM)}
\label{sec:wm}
Based on the Wavelet Trees \cite{WT03}, the Wavelet Matrix \cite{CNO15} is a structure that is able to perform, among others, operations of $rank_a(S,i)$ and $select_a(S,i)$ $\forall a \in \Sigma$ and a sequence $S[1..n]$ over the vocabulary $\Sigma$ in $O(log\sigma)$ time while using $n\lceil log_2\sigma\rceil~+~o(n)$ bits of space, begin $\sigma = |\Sigma|$.

The WM is built with $\lceil log_2\sigma\rceil$ levels, each level having a bitvector $B_i$ with rank and select capabilities, where $B_1$ contains the most significant bit of every symbol $a \in S$, $B_2$ contains the second most significant bit and so forth. To further explain how these bits are positioned, we must consider $a_k$ as the $k$th bit of $a$ in significance, and $B^{-1}_i[a_k]$ as the position of the bit $a_k$ from $a$ in the bitvector $B_i$. Then, 
\[
    B_i[j] = \left\{\begin{array}{lr}
        S[j]_1, & \text{iff } i=1\\
        a_i, & \text{iff } i>1 \wedge (a_{i-1}=0 \wedge j=rank_0(B_{i-1},B^{-1}_{i-1}(a_{i-1}))) \\
        & \vee~(a_{i-1}=1~\wedge~j=rank_0(B_{i-1},n)~+~rank_1(B_{i-1},B^{-1}_{i-1}(a_{i-1})))
        \end{array}\right.
\]

That is, $B_1$ contains all the bits $a_1 \forall a \in S$, in the same order as in S. After that, $B_2$ contains the $a_2$ bits from those $a$ such as $a_1 = 0$ first, followed by those with $a_1 = 1$. That way, all the position of each $a_i$ in $B_i$ depends first by the value of $a_{i-1}$ and later by their position in $B_{i-1}$. Refer to the structures \texttt{WML} and \texttt{WMJ} in Figure~\ref{fig:example_ctr} for examples of one and two-leveled WM. Additionally, there exists a conceptual \textit{leaf level}, that is formed by the final position of every $a$ after applying the recursion on the last level. Because the sorting of each level depends on the values of the previous most significant bits, in the leaf level all symbols are sorted by their reverse representation in bits.

This structure allows to answer the following operations in $O(log\sigma)$ time:
\begin{itemize}
    \item $access(S,i)$ returns the value in any position in the original sequence $S$ by following through the levels of the WM using the $rank$ operation on bitvectors. If $B_1[i]$ is 0, then $B_2[rank_0(B_1,i)]$ must be accessed next. Otherwise, it is $B_2[rank_0(B_1,n) + rank_1(B_1,i)]$. This must be recursively applied until the leaf level is reached, and the traversed bits will compose the value of $S[i]$.
    \item $rank_a(S,i)$ is calculated with the same operations as in $access$, with the difference that in this case we know whether we need to use $rank_0$ or $rank_1$ on each bitvector as the value of the symbol $a$ is known. To calculate the number of occurrences of $a$ in $S[1..i]$ we must simply subtract the position reached in the leaf level to the position of the first occurrence of $a$ on that level, which can be either stored for each symbol in $O(\sigma)$ bits or calculated by making an analogous traversal from the first position of $S$.
    \item $select_a(S,i)$ first $i$ must be added to the first position of $a$ in the leaf level, which as for $rank$, can be either stored or calculated. After obtaining this position $j$, the WM must be traversed in reverse order using $select$ on bitvectors until the first level is reached. When $a_i=0$ the traversal from the lower level position $B_{i+1}[j]$ must be as $select_0(B_i,j)$, while when $a_i=1$, it is done as $select_1(B_i,j-rank_0(B_{i},n))$.
    \item $range_{a,b}(S,i,j)$ returns the number of occurrences of the symbols between $a$ and $b$ in $S[i..j]$. This operation was first introduced in \cite{gagie2012new} for Wavelet Trees and later supported by the Wavelet Matrix \cite{CNO15}, and we make extensive use of it in this work. It is solved with two simultaneous traversals similar to $rank$ over $i$ and $j$, only that it is possible that at some levels it is required to calculate both $rank_0$ and $rank_1$. However, the worst case time complexity of $O(log\sigma)$ is maintained, due to the fact that it is not necessary to reach the leaf level for all the symbols in $a..b$\footnote{As long as $a\neq b$. Otherwise, $rank_a(S,j)-rank_a(S,i)$ can be used.}.
\end{itemize}

While a compression method is proposed in \cite{CNO15} by using canonical Huffman encoding on the symbols, it could not be applied in our work because it severely reduces the efficiency of $range_{a,b}(S,i,j)$. Instead, we focused on compressing the bitvectors and using ad-hoc optimizations to reduce the average height of our WMs.

\section{Our model for compact trip representation}
In our previous structures proposed in \cite{brisaboa2018new}, we propose a work-in-progress model to represent the demand information for a public transportation network, as seen in the Figure~\ref{fig:er}.

\begin{figure}
%\centering
\includegraphics[width=\textwidth]{NetworkER.pdf}
\caption{An (updated) ER diagram representing the work-in-progress model for user trips in public transportation}
\label{fig:er}
\end{figure}

These are the main elements from our model:
\begin{itemize}
    \item A \textbf{stop\_place} is a physical stop with a location, on which several lines may make stops.
    \item A \textbf{line} is an ordered sequence of stop places that can be traveled by a transport vehicle, such as a bus or a train. It only considers one direction. For this reason, there is often a different and complementary line for the opposite direction.
    \item A \textbf{journey} is a single traversal of a transport vehicle over a line. It can be seen as a vehicle trip, instead of a user trip.
    \item A \textbf{stage} is formed by a boarding from a stop and alighting to another from the same single line and journey.
    \item An \textbf{user\_trip} is a concatenation of several stages, until the final destination (alighting stop of the last stage) is reached.
\end{itemize}

This approach allows us to treat the information in a layered fashion: the bottom layer is a static network representation, formed by the line and stop\_place entities, the middle layer are the journeys made by vehicles that make stops at specific times, while the top layer are the trips made by the users over these vehicle journeys. In the Figure~\ref{fig:example_network} we show an example for the two bottom layers. Our proposed implementation can be found in Section~\ref{seq:ps}.

\begin{figure}
\includegraphics[width=\textwidth]{example_network.eps}
\caption{An example network for our model, with two lines and five stops}
\label{fig:example_network}
\end{figure}

Finally, it is possible to introduce a \textbf{user} identity, with an anonymized identifier to segregate trips by users. However, we do not consider such information useful for the kind of analysis that this work focuses on. If needed in the future, this additional entity could be trivially integrated in our representation.

\subsection{Relevant queries}
\label{seq:rq}
In the context of public transportation networks, we are interested in solving two kinds of queries:

\begin{enumerate}[A)]
    \item Aggregation of passengers, asking for the gross number of users that boarded or alighted within an area and a time window. Furthermore, it can be also interesting to obtain the average load of a bus or a train between any two stops from its line.\marginpar{\tiny meteremos algún ejemplo de las consultas que después implementaremos}
    \item Movement patterns, or queries that focus on the sequence of trip stages. Examples of such queries are the number of times a stop was used to switch lines or the number of trips that started on a stop with another specific stop as the final destination. 
\end{enumerate}

En concreto, en este paper nos hemos centrado en ...
\begin{itemize}
    \item  consulta 1
    \item consutla 2
    
    
\end{itemize}

\section{Proposed Structures}
\label{seq:ps}

As of today, we are not aware of any indexing structure that would allow to efficiently represent trajectories that could also support all the kinds of queries described in Section~\ref{seq:rq}. For this reason, we propose two data structures, \acumm~and~\ctr. The former is targeted for queries of type A, solving most aggregation queries in constant time, while the later can be used for queries of type B.

\subsection{Common Structures}
Both \acumm~and \ctr~need a network representation to be operated, along with information about the transport vehicle journeys. Therefore, the following structures represent a network with stops $s_i \in S = \{1,...|S|\}$, lines $l_i \in L = \{1,...|L|\}$ and journeys $j_i \in J^l = \{1,...|J^l|\}$. It is important to state that journeys are \textbf{not} identified by $j_i$, as the same $j_i$ can belong to several $J^l$ from different lines, so we speak about journey \textbf{codes} (jcodes) instead of journey identifiers.

\begin{itemize}
    \item $lineStop_i(j)$ is the $j$th stop of line $l_i$
    \item $stopLine_i(j)$ is the $j$th line that makes a stop at the stop $s_i$
    \item $avgTime_i(j)$ is the average time in seconds that it takes for a vehicle of line $l_i$ to reach its $j$th stop from the start of a journey
    \item $initialTime_i(k)$ is the starting time of the journey $j_k$ for line $l_i$
\end{itemize}

With the exception of $initialTime$, all these structures are small enough to be represented using plain fixed-length integer arrays. In the case of $initialTime$, its size naturally grows with the amount of trips that are indexed, thus there is a motivation to reduce its size, which can be easily achieved with any technique that works on posting lists or sequences of strictly increasing numbers. In our work we used a simplified Vbyte+ANS compression described in \cite{moffat2017ans} using the Zstd library\footnote{https://github.com/facebook/zstd}. In order to facilitate searches and random access, we introduced fixed-length samples on configurable intervals.

An example of these structures interacting together can be found at the Algorithm~\ref{alg:jcodes}, the the function \FuncSty{lower\_bound} is a binary search that returns the index of the first occurrence that is no lesser than the queried value, while \FuncSty{upper\_bound} returns the index of the last no greater occurrence.

\begin{algorithm}[H]
\SetKwData{l}{$l$}\SetKwData{lz}{l$_z$}\SetKwData{s}{s}\SetKwData{sz}{s$_z$}\SetKwData{ta}{t$_a$}\SetKwData{tz}{t$_z$}\SetKwData{pattern}{pattern}\SetKwData{left}{left}\SetKwData{right}{right}\SetKwData{csa}{CSA}\SetKwData{wmj}{WMJ}\SetKwData{leftzero}{left$_0$}\SetKwData{rightzero}{right$_0$}\SetKwData{i}{i}\SetKwData{z}{z}\SetKwData{ja}{j$_a$}\SetKwData{jz}{j$_z$}\SetKwData{n}{n}\SetKwData{ap}{a'}\SetKwData{zp}{z'}\SetKwData{offset}{offset}
 \SetKwFunction{GetBounds}{GetBounds}\SetKwFunction{GetJCodes}{GetJCodes}\SetKwFunction{GetCount}{GetCount}\SetKwFunction{GetPsi}{$\Psi$}\SetKwFunction{GetRangeSpecial}{GetRange$^*$}\SetKwFunction{bsearch}{binary\_search}\SetKwFunction{lbound}{lower\_bound}\SetKwFunction{ubound}{upper\_bound}
 \SetKwProg{Fn}{Function}{\string:}{}
 
 \Fn{\GetJCodes{\l,\s,\ta,\tz}}{
 \KwData{line \l, stop \s, times \ta,\tz}
 \KwResult{jcodes for \ta and \tz}
 \BlankLine
 \offset $\leftarrow$ $avgTime_{\l}(\bsearch{$lineStop_\l$, \s})$\;
 \Return{\lbound{$initialTime_\l$, \ta-\offset}, \ubound{$initialTime_\l$, \tz-\offset}}\;
 }
 
 \caption{Obtaining the codes of the journeys from the line \l that should arrive to the stop \s within the time range given by \ta and \tz}
 \label{alg:jcodes}
\end{algorithm}

\subsection{\acumm}
As it has been stated previously in this paper, nowadays it could be relatively simple to gather massive information about user trips in every public transport; however, it is not necessary to store individually each trip. If there are two (or more) commuters sharing the same bus (train/tram/etc), they are also sharing the route, the stops (the time of each stop) and even the network. Therefore, a structure storing the aggregated data of the user trips would be a handy solution to solve (at least) queries of type A presented in section 3.

Thus, we propose the T-Matrix (this is the 3rd name it has), an accumulated solution that involves two-dimensional matrices of integers enabling aggregated queries by row, column, or window/range. In the context of a public trasnportation network, it would by useful to solve flexible line-centered queries; that is, queries that support aggregation by any dimension. Therefore, it could be possible to aggregate either by time-interval (e.g. number of users got on at any stop of the line on 2019/01/02); by stop (e.g. number of commuters that got on a bus at stop S); or by stop and time-interval.

In a naïve representation, it would only be necessary a two-dimensional matrix having stops as columns and journeys as rows, so each cell would have an integer representing the number of passengers that got on the vehicle at a specific stop in a particular time (journey). The main issue with this approach is that for each query it would be necessary to sum integer by integer each cell of the solution; hence, if we are trying to compute how many people got on a bus in several consecutive sotps during a time interval (several consecutive journeys) it would be necessary to sum all the cells within the matrix that match these journeys and stops.

On the other hand, T-Matrix is based on this naive proposal but instead of storing each cell as a simple integer it assigns an accumulated value to each slot, being the top left cell the smaller number and the bottom right position the cumulative value resulting from adding all the previous cells. Despite having larger numbers in almost every slot of the matrix, this approach allows to apply the dynamic programing formula that follows:

$\mathsf{countRange((x_1,y_1),(x_2,y_2))} \leftarrow {M(x_2,y_2)} - {M(x_2,y_1-1)} - {M(x_1-1,y_2)} + {M(x_1-1,y_1-1)}$.

The combination of this operations with our proposed accumulative matrix enables to compute the same two-dimensional (or one-dimensional) queries in constant time O(1), as it is only neccesary to access and sum four cells in all the matrix.

EXAMPLE

One simple way of dealing with the growth of numbers in our cumulative solution is just apply a kind of sampling with differences; in this way, a basic example could be keep the middle column m ← (n s + 1)/2 explicitly, and representing the values in the other columns m±k as the difference with respect to column m.

\subsection{CTR version de spire...}
y despues la variante nueva (CTR2M).

\subsection{\ctr}
A user trip can be represented by the stops from the transportation system that were boarded by a user, so from now on we will consider a trip as a sequence of triplets $<s,l,j>$, where $s$, $l$ are, respectively, stop and line identifiers, while $j$ are the journey codes corresponding to the journeys that compose the trip. These triplets describe a trip in a consecutive fashion, on the same order as the stops were boarded. Additionally, as we are interested in knowing where the trips end, we also represent the last stop where the user has alighted, which line and journey will logically match the line and journey of the last boarding stop. Although it is generally hard to obtain information about the last destination stop of a trip, many transportation companies are investing effort in providing it, either by implementing systems to keep track of users as they leave their system or estimating it based on previous trips made by that user\marginpar{[CITATION NEEDED]}.

\ctr~is built first by sorting all trips. If we consider that a trip is composed by $n$ of the $<s_i,l_i,j_i>,~1\leq i\leq n$ triplets previously described, where the first triplet corresponds to the first boarded stop and the last triplet corresponds to the last alighted stop (final destination), then the collection of trips is sorted by the key $s_1,s_n,l_1,j_1$. That is, trips are initially sorted by the first boarded stop identifier. If these are equal, they are then sorted by their last stop identifier, analogously followed by the line identifier and journey code of the first stop. Figure~\ref{fig:example_ctr} displays an example of a correct sorting of trips.

\begin{figure}[hbt!]
\includegraphics[width=\textwidth]{example_trips.eps}
\caption{An example of five trips represented on \ctr with the optimizations for \texttt{WML} and \texttt{WMJ}, and sections for each stop delimited by dotted lines}
\label{fig:example_ctr}
\end{figure}

We use three complementary structures to represent each component of the sequence, as shown in Figure~\ref{fig:example_ctr}:
\begin{enumerate}[(i)]
    \item An adapted Compressed Suffix Array (\texttt{CSA}) over the stop identifiers of all trips, concatenated into a string with additional terminator symbols $\$$ appended at the end of each trip. While in the final CSA we assign these $\$$ a lexicographical value of 0 (thus smaller than any stop identifier), we assign them different values during the construction of the suffix array (A) to ensure that the entries for $\$$ in A maintain the same order as in the original text. Finally, we make a modification on $\Psi$ to make the entries of each $\$$ point to the start of its own trip instead of the next one. These two modifications are proven necessary for our implemented queries, at the expense of losing some of the properties of a classic CSA.
    \item \texttt{WML}: Aligned to the entries of (i) there is a Wavelet Matrix (WM) for the line identifiers of each stop. Aligned to the $\$$ section we duplicate the starting lines of each trip. As a trivial optimization, we build a separate WM for every stop, allowing us to save space due to the fact that a single stop does not usually belong to many lines, thus the average height of these WM is no larger (and usually smaller) than the height of a single WM.
    \item \texttt{WMJ}: A WM of jcodes aligned to the leaves of (ii). Note that this makes this structure dependant on (ii), which is coherent with the fact that journey codes themselves are relative to the line identifier. In case (ii) implements the optimization described, the entries of the WM must also be rearranged to match the delimited stops.
\end{enumerate}

As \ctr is a complete representation of the collection of trips, we are able to extract any trip using the structures described. \marginpar{The idea here is that explaining how to extract will help understand the more complex FromXtoY query later} The algorithm to extract a trip is shown in the Algorithm~\ref{alg:extract}, where \FuncSty{Rank} and \FuncSty{Select} operate over the bitvector $D$ from our \texttt{CSA}, \FuncSty{WML}{(s$_a$)} is the WM corresponding to the stop \DataSty{s$_a$} in the optimized version of \texttt{WML} and \FuncSty{TrackDown} returns the leaf index of a WM given a root index. In a practical implementation, it is not needed to access \texttt{WML} and \texttt{WMJ} for the line identifier and jcode of the last stop of the trip, as they will always match the previous ones.

\begin{algorithm}[hbt!]
\SetKwData{la}{$l_a$}\SetKwData{lz}{$l_z$}\SetKwData{sa}{s$_a$}\SetKwData{sz}{s$_z$}\SetKwData{ta}{t$_a$}\SetKwData{tz}{t$_z$}\SetKwData{pattern}{pattern}\SetKwData{left}{left}\SetKwData{right}{right}\SetKwData{csa}{CSA}\SetKwData{wmj}{WMJ}\SetKwData{leftzero}{left$_0$}\SetKwData{rightzero}{right$_0$}\SetKwData{a}{a}\SetKwData{z}{z}\SetKwData{ja}{j$_a$}\SetKwData{jz}{j$_z$}\SetKwData{n}{n}\SetKwData{ap}{a'}\SetKwData{zp}{z'}\SetKwData{offset}{offset}\SetKwData{i}{i}\SetKwData{trip}{trip}
 \SetKwFunction{GetRange}{GetRange}\SetKwFunction{GetJCodes}{GetJCodes}\SetKwFunction{GetCount}{GetCount}\SetKwFunction{GetPsi}{$\Psi$}\SetKwFunction{GetRangeSpecial}{GetRange$^*$}\SetKwFunction{wml}{WML}\SetKwFunction{TrackUp}{TrackUp}\SetKwFunction{Select}{Select}\SetKwFunction{fxy}{FromXtoY\_full}\SetKwFunction{extract}{Extract\_trip}\SetKwFunction{access}{Access}\SetKwFunction{rank}{Rank}\SetKwFunction{TrackDown}{TrackDown}
 \SetKwProg{Fn}{Function}{\string:}{}
 
 \Fn{\extract{\i}}{
 \KwData{trip number \i}
 \KwResult{Sequence of tuples $<s,l,j>$ that compose the trip}
 \BlankLine
 \trip $\leftarrow$ []\;
 \a  $\leftarrow$ \GetPsi{\csa, \i}\;
 \sa $\leftarrow$ \rank{\csa,\a}\;
 \BlankLine
 \While{\sa $\neq$ 0}{
    \z $\leftarrow$ \Select{\csa,\sa}\;
    \la $\leftarrow$ \access{\wml{\sa}, \a-\z}\;
    \ja $\leftarrow$ \access{\wmj, \TrackDown{\wml{\sa}, \a-\z}+\z}\;
    append $<\sa,\la,\ja>$ to \trip\;
    \a  $\leftarrow$ \GetPsi{\csa, \i}\;
    \sa $\leftarrow$ \rank{\csa,\a}\;
 }
 \BlankLine
 \Return{\trip}\;
 }
 
 \caption{Extracting the trip \DataSty{i} from \ctr where \FuncSty{CSA}, \FuncSty{WML} and \FuncSty{WMJ} are the structures previously described in (i), (ii) and (iii), respectively}
 \label{alg:extract}
\end{algorithm}

A more complex query that we can solve with \ctr is ``number of trips that started from a stop \DataSty{s$_a$} and ended at a stop \DataSty{s$_z$}'', which can be further restricted to specific starting and ending lines and a time window. The pseudocode for the full version of such query can be found at the Algorithm~\ref{alg:xy}. This algorithm relies heavily on the abstract function \FuncSty{GetRange}, which when applied to a CSA, delimits the range of entries of $\Psi$ that match a queried string pattern, while on a WM it reports the range in the last level of a WM corresponding to the entries of a queried symbol within a range in the encoded sequence (equivalent to two \FuncSty{TrackDown} operations on the first and last occurrence of the queried symbol, but more time efficient)\marginpar{Briefly describe WM in previous works and refer to that section for complexity of these queries}.

\begin{algorithm}[hbt!]
\SetKwData{la}{$l_a$}\SetKwData{lz}{$l_z$}\SetKwData{sa}{s$_a$}\SetKwData{sz}{s$_z$}\SetKwData{ta}{t$_a$}\SetKwData{tz}{t$_z$}\SetKwData{pattern}{pattern}\SetKwData{left}{left}\SetKwData{right}{right}\SetKwData{csa}{CSA}\SetKwData{wmj}{WMJ}\SetKwData{leftzero}{left$_0$}\SetKwData{rightzero}{right$_0$}\SetKwData{a}{a}\SetKwData{z}{z}\SetKwData{ja}{j$_a$}\SetKwData{jz}{j$_z$}\SetKwData{n}{n}\SetKwData{ap}{a'}\SetKwData{zp}{z'}\SetKwData{offset}{offset}
 \SetKwFunction{GetRange}{GetRange}\SetKwFunction{GetJCodes}{GetJCodes}\SetKwFunction{GetCount}{GetCount}\SetKwFunction{GetPsi}{$\Psi$}\SetKwFunction{GetRangeSpecial}{GetRange$^*$}\SetKwFunction{wml}{WML}\SetKwFunction{TrackUp}{TrackUp}\SetKwFunction{Select}{Select}\SetKwFunction{fxy}{FromXtoY\_full}
 \SetKwProg{Fn}{Function}{\string:}{}
 
 \Fn{\fxy{\la,\lz,\sa,\sz,\ta,\tz,\n}}{
 \KwData{lines \la,\lz, stops \sa,\sz, times \ta,\tz and length of the sequence \n}
 \KwResult{Number of occurences}
 \BlankLine
 \pattern $\leftarrow \{\sz,0,\sa\}$\;
 \left,\right $\leftarrow$ \GetRange{\csa, $0$, \n, \pattern}\;
 \leftzero $\leftarrow$ \GetPsi{\csa, \left}\;
 \rightzero $\leftarrow$ \GetPsi{\csa, \right}\;
 \tcp{\right-\left = \rightzero-\leftzero}
 \a,\z $\leftarrow$ \GetRange{\wml{$0$},\leftzero,\rightzero,\la}\;
 \ja,\jz $\leftarrow$ \GetJCodes{\la,\sa,\ta,\tz}\;
 \a,\z $\leftarrow$ \GetRangeSpecial{\wmj,\a,\z,\ja,\jz}\;
 \ap $\leftarrow$ \TrackUp{\wml{$0$},\a}\;
 \zp $\leftarrow$ \TrackUp{\wml{$0$},\z}\;
 \tcp{\z-\a = \zp-\ap}
 \offset $\leftarrow$ \Select{\csa,\sz}\;
 \a,\z $\leftarrow$ \GetRange{\wml{\sz},\left-\offset~$+$~\ap-\leftzero,
 \left-\offset~$+$~\zp-\leftzero,\lz}\;
 \ja,\jz $\leftarrow$ \GetJCodes{\lz,\sz,\ta,\tz}\;
 \Return{\GetCount{\wmj,\offset~+~\a,\offset~+~\z,\ja,\jz}}\;
 }
 
 \caption{Querying for all features on \ctr}
 \label{alg:xy}
\end{algorithm}

We will now proceed to explain the Algorithm~\ref{alg:xy} line by line:
\begin{itemize}
    \item In \textbf{lines 2-3}, we query our \FuncSty{CSA} for the pattern consisting of the destination stop \DataSty{s$_z$}, followed by a 0 (the code for the $\$$ symbol) and finally the origin stop \DataSty{s$_a$}. This results in a range of entries within the section of \DataSty{s$_z$} that belong to our queried trips, because the trips were made circular in $\Psi$, so each $\$$ points to the beginning of its own trip. If we were not interested in restricting lines nor time, the function would end here, returning \DataSty{right}-\DataSty{left}.
    
    \item In \textbf{lines 4-6} we obtain the corresponding range in the section of $\$$ by accessing \FuncSty{$\Psi$}. Note that because of how the sorting of the $\$$ symbols was altered during the construction of the suffix array, these two ranges are equal in size, as the comment in line 6 points out.
    
    \item In \textbf{line 7} we query \texttt{WML} in the $\$$ section, within the range previously obtained, for the queried starting line \DataSty{l$_a$}, obtaining the range of its occurrences in the last level, delimited by \DataSty{a} and \DataSty{z}. Note that if the \ctr was constructed without the optimization that separates \texttt{WML} in sections, this line would be exactly the same, save for the query being on a \DataSty{WML} that would encode the whole sequence of lines instead of just the \DataSty{WML}{(0)} for $\$$.
    
    \item In \textbf{line 8} we obtain the range of jcodes for the journeys from the line \DataSty{l$_a$} that would pass through the stop \DataSty{s$_a$} within the time window delimited by \DataSty{t$_a$} and \DataSty{t$_z$}, using the function \FuncSty{GetJCodes} from Algorithm~\ref{alg:jcodes}.
    
    \item In \textbf{line 9} we operate over a range of \texttt{WMJ} that encodes a non-decreasing sequence of jcodes, given that within the same origin stop, final stop and starting line, the $\$$ were sorted by the starting journey code of their trips. This allows us to use a specially modified version of \FuncSty{GetRange} that is able to return the range of indexes on the first level of the WM instead of the last one. This is equivalent to finding the lower and upper bounds for the range \DataSty{j$_a$}$..$\DataSty{j$_z$} via binary searches in \FuncSty{WMJ} from \DataSty{a} to \DataSty{z}, but much more efficient.
    
    \item In \textbf{lines 10-12} we use the \FuncSty{TrackUp} operation, which is the inverse of \FuncSty{TrackDown}: it returns the root index given a leaf index of a WM. In this case, as the \FuncSty{a} and \FuncSty{z} we obtained in the previous step are also indexes in the last level of the lines WM, we use \FuncSty{TrackUp} to translate that range of indexes to the root of \texttt{WML} and therefore to the entries of the \texttt{CSA} as well. Note that this is a range inside the $\$$ section for trips with the same origin stop, final stop and starting line that includes all the trips for jcodes that span from \DataSty{j$_a$} to \DataSty{j$_z$}. The properties of our adapted \texttt{CSA} also ensure that this range maintains the same size after translation and it can also be directly translated to a range in the \DataSty{s$_z$}.
    
    \item In \textbf{line 13} we obtain the starting index of the section for the stop \DataSty{s$_z$} with a \FuncSty{Select} operation over the bitvector D from \texttt{CSA}. This is necessary for operating on \texttt{WML} and \texttt{WMJ} to restrict the line and journeys for the final stop.
    
    \item In \textbf{line 14} the range \DataSty{a'}$..$\DataSty{z'} is trivially translated to the section for \DataSty{s$_z$} where we query \texttt{WML} to obtain the subrange for the line \DataSty{l$_z$}. Remember that \DataSty{WML}{(s$_z$)} represents only the lines for \DataSty{s$_z$}, therefore both the translated indexes and the resulting subrange indexes are relative and must be adjusted by \DataSty{offset}. This would have not been necessary if the optimization was not implemented, and absolute indexes would have been used.
    
    \item In \textbf{line 15} we obtain the jcode range analogously to line 8, but this time for \DataSty{l$_z$} and \DataSty{s$_z$}.
    
    \item In \textbf{line 16} we return the number of entries of \texttt{WMJ} between \DataSty{j$_a$} and \DataSty{j$_z$} within our final subrange. The function \FuncSty{GetCount} does not report any range boundaries as \FuncSty{GetRange} does, but simply returns the number of occurrences. Of course, the time complexity of this operation is still proportional to the height of the WM even though the matching entries can be scattered (not delimiting a contiguous range).
\end{itemize}

It is trivial to reuse the Algorithm~\ref{alg:xy} to answer queries with less constrains. For example, if we were only interested in restricting the starting line, we could return \DataSty{z}-\DataSty{a} after line 7. Or if we only wanted to restrict the ending line and time, we can do it by skipping the lines 4-12, and using directly \FuncSty{GetRange}{(\FuncSty{WML}{(s$_z$)},left-offset,right-offset,l$_z$)} in line 14. The complexity would increase if we restricted by a time window but not by lines, as would need to iterate through all possible lines for \DataSty{s$_a$} and \DataSty{s$_z$} to obtain the jcodes for each line and perform these operations on \texttt{WML} and \texttt{WMJ}. Fortunately, the number of lines that a single stop can belong to tends to be rather small in practice, thus with a careful implementation that avoids repeating computation the performance of such query scales well, as will be shown later in Section~\ref{sec:exp}. Finally, to obtain only the trips that started on a given stop we would simply need to set \DataSty{pattern} to $\{0,s_a\}$ in line 2, or alternatively to $\{s_z,0\}$ for the final stop, and skipping the operations on the sections of \DataSty{s$_z$} or $\$$, respectively.

Of course, \ctr can also be used to efficiently obtain other interesting information about trips, such as the top k most boarded stops, as shown in \cite{brisaboa2018compact}, with the additional possibility of differentiating stops that are only used to switch lines in \ctr. However, there is no known way of using this representation to obtain other kinds of information efficiently (e.g. the number of passengers in a journey between two stops).

\section{Experiments}
\label{sec:exp}
For space, I propose to compare with our previous structures and with a plain representation using bits per symbol (bps). Otherwise, the baseline we select for our $\%$ can be misleading.

For time, we will compare against SPIRE 2018, and maybe, IF WE HAVE TIME, with a plain postgresql baseline. Experiments will be executed in Compostela2 or whatever we'll have available.

\section{Conclusions}
Speak about how cool would it be to have a single structure that could to it all. Pitch for our next paper with Gonzalo!

\subsection{A Subsection Sample}
Please note that the first paragraph of a section or subsection is
not indented. The first paragraph that follows a table, figure,
equation etc. does not need an indent, either.

Subsequent paragraphs, however, are indented.

\subsubsection{Sample Heading (Third Level)} Only two levels of
headings should be numbered. Lower level headings remain unnumbered;
they are formatted as run-in headings.

\paragraph{Sample Heading (Fourth Level)}
The contribution should contain no more than four levels of
headings. Table~\ref{tab1} gives a summary of all heading levels.

\begin{table}
\caption{Table captions should be placed above the
tables.}\label{tab1}
\begin{tabular}{|l|l|l|}
\hline
Heading level &  Example & Font size and style\\
\hline
Title (centered) &  {\Large\bfseries Lecture Notes} & 14 point, bold\\
1st-level heading &  {\large\bfseries 1 Introduction} & 12 point, bold\\
2nd-level heading & {\bfseries 2.1 Printing Area} & 10 point, bold\\
3rd-level heading & {\bfseries Run-in Heading in Bold.} Text follows & 10 point, bold\\
4th-level heading & {\itshape Lowest Level Heading.} Text follows & 10 point, italic\\
\hline
\end{tabular}
\end{table}


\noindent Displayed equations are centered and set on a separate
line.
\begin{equation}
x + y = z
\end{equation}
Please try to avoid rasterized images for line-art diagrams and
schemas. Whenever possible, use vector graphics instead (see
Fig.~\ref{fig1}).

\begin{figure}
\includegraphics[width=\textwidth]{fig1.eps}
\caption{A figure caption is always placed below the illustration.
Please note that short captions are centered, while long ones are
justified by the macro package automatically.} \label{fig1}
\end{figure}

\begin{theorem}
This is a sample theorem. The run-in heading is set in bold, while
the following text appears in italics. Definitions, lemmas,
propositions, and corollaries are styled the same way.
\end{theorem}
%
% the environments 'definition', 'lemma', 'proposition', 'corollary',
% 'remark', and 'example' are defined in the LLNCS documentclass as well.
%
\begin{proof}
Proofs, examples, and remarks have the initial word in italics,
while the following text appears in normal font.
\end{proof}

%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.

\bibliographystyle{splncs04}
\bibliography{refs}

\end{document}
